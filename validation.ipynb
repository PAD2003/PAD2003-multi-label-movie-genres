{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (from baseline notebooks):  tensor(0.1966, device='cuda:0')\n",
      "\n",
      " Classification reports\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.15      0.10      0.12        31\n",
      "    Thriller       0.30      0.32      0.31       106\n",
      "     Fantasy       0.07      0.14      0.10         7\n",
      "      Horror       0.36      0.21      0.27        75\n",
      "      Sci-Fi       0.36      0.33      0.34        48\n",
      "      Comedy       0.74      0.30      0.43       247\n",
      " Documentary       0.09      0.40      0.15        30\n",
      "   Adventure       0.00      0.00      0.00        48\n",
      "   Film-Noir       0.11      0.17      0.13         6\n",
      "   Animation       0.32      0.67      0.43        21\n",
      "     Romance       0.29      0.13      0.18        94\n",
      "       Drama       0.65      0.26      0.37       309\n",
      "     Western       0.25      0.29      0.27        14\n",
      "     Musical       0.20      0.38      0.26        13\n",
      "      Action       0.34      0.30      0.32        90\n",
      "     Mystery       0.00      0.00      0.00        18\n",
      "         War       0.08      0.04      0.05        25\n",
      "  Children's       0.35      0.58      0.43        48\n",
      "\n",
      "   micro avg       0.31      0.27      0.29      1230\n",
      "   macro avg       0.26      0.26      0.23      1230\n",
      "weighted avg       0.45      0.27      0.31      1230\n",
      " samples avg       0.25      0.26      0.24      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from src.models.movie_genre_module import MovieGenreModule\n",
    "from src.data.components.movie_genre_dataset import MovieGenreDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# config\n",
    "ckpt_path = \"logs/train/runs/2023-12-24_11-26-55/checkpoints/epoch_021.ckpt\"\n",
    "threshold_decode = 0.3\n",
    "device = 'cuda'\n",
    "num_classes = 18\n",
    "genre_file = 'data/ml1m/content/dataset/genres.txt'\n",
    "excel_path =  \"data/report/experiment_2_renet50_datav2.xlsx\" # chang this\n",
    "results_path = \"data/inference_results/renet50_datav2.npz\" # chang this\n",
    "save_golder_label = None\n",
    "\n",
    "# excel_path =  None\n",
    "# results_path = None\n",
    "# save_golder_label = None\n",
    "\n",
    "\n",
    "# helper functions\n",
    "def decode_label(output_probability):\n",
    "    output_label = []\n",
    "    for each_output in output_probability:\n",
    "        output_label.append([0 if x < threshold_decode else 1 for x in each_output])\n",
    "    return output_label\n",
    "\n",
    "# components\n",
    "model = MovieGenreModule.load_from_checkpoint(ckpt_path)\n",
    "test_set = MovieGenreDataset(\n",
    "    set='ensemble_test',\n",
    "    data_file='data/ml1m/content/dataset/movies_test.dat',\n",
    "    folder_img_path='data/ml1m/content/dataset/ml1m-images',\n",
    "    genre_file=genre_file\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=64,\n",
    "    num_workers=32,\n",
    "    pin_memory=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# compute\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "golden_label = []\n",
    "predict_label = []\n",
    "predict_probs = []\n",
    "\n",
    "f1 = MultilabelF1Score(num_labels=num_classes, threshold=threshold_decode, average='macro')\n",
    "f1 = f1.to(device)\n",
    "f1_all = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_tensor, genre_tensor in test_loader:\n",
    "        img_tensor = img_tensor.to(device)\n",
    "        genre_tensor = genre_tensor.to(device)\n",
    "        \n",
    "        probs = model(img_tensor)\n",
    "        preds = torch.tensor(decode_label(probs), device=\"cuda\")\n",
    "        \n",
    "        predict_probs.extend(probs.cpu().numpy())\n",
    "        predict_label.extend(preds.cpu().numpy())\n",
    "        golden_label.extend(genre_tensor.cpu().numpy())\n",
    "        \n",
    "        f1_batch = f1(probs, genre_tensor)\n",
    "        f1_all += f1_batch\n",
    "\n",
    "print('F1 (from baseline notebooks): ', f1_all/len(test_loader))\n",
    "\n",
    "# report\n",
    "predict_probs = np.array(predict_probs)\n",
    "predict_label = np.array(predict_label)\n",
    "golden_label = np.array(golden_label)\n",
    "\n",
    "with open(genre_file, 'r') as f:\n",
    "    genre_all = f.readlines()\n",
    "genre_all = [x.replace('\\n', '') for x in genre_all]\n",
    "print(\"\\n Classification reports\")\n",
    "print(classification_report(golden_label, predict_label, target_names=genre_all))\n",
    "\n",
    "# export\n",
    "if excel_path is not None:\n",
    "    report = classification_report(golden_label, predict_label, target_names=genre_all, output_dict=True)\n",
    "    df = pd.DataFrame(report)\n",
    "    df = df.transpose()\n",
    "    df.to_excel(excel_path)\n",
    "\n",
    "if results_path is not None:\n",
    "    with open(results_path, 'wb') as f:\n",
    "        np.save(f, predict_probs)\n",
    "\n",
    "if save_golder_label is not None:\n",
    "    with open(save_golder_label, 'wb') as f:\n",
    "        np.save(f, golden_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (from baseline notebooks):  tensor(0.2595, device='cuda:0')\n",
      "\n",
      " Classification reports\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.10      0.19      0.13        31\n",
      "    Thriller       0.36      0.38      0.37       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.66      0.64      0.65        75\n",
      "      Sci-Fi       0.53      0.54      0.54        48\n",
      "      Comedy       0.55      0.53      0.54       247\n",
      " Documentary       0.14      0.03      0.05        30\n",
      "   Adventure       0.29      0.29      0.29        48\n",
      "   Film-Noir       0.00      0.00      0.00         6\n",
      "   Animation       0.57      0.19      0.29        21\n",
      "     Romance       0.29      0.23      0.26        94\n",
      "       Drama       0.46      0.84      0.59       309\n",
      "     Western       0.12      0.07      0.09        14\n",
      "     Musical       0.00      0.00      0.00        13\n",
      "      Action       0.40      0.44      0.42        90\n",
      "     Mystery       0.30      0.17      0.21        18\n",
      "         War       0.14      0.12      0.13        25\n",
      "  Children's       0.64      0.48      0.55        48\n",
      "\n",
      "   micro avg       0.44      0.51      0.47      1230\n",
      "   macro avg       0.31      0.29      0.28      1230\n",
      "weighted avg       0.43      0.51      0.45      1230\n",
      " samples avg       0.47      0.54      0.47      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from src.models.hybrid_movie_genre_module import HybridMovieGenreModule\n",
    "from src.data.components.hybrid_movie_genre_dataset import HybridMovieGenreDataset\n",
    "from torch.utils.data import DataLoader \n",
    "import torch\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# config\n",
    "ckpt_path = \"logs/train/runs/2023-12-26_02-14-54/checkpoints/epoch_029.ckpt\"\n",
    "threshold_decode = 0.3\n",
    "device = 'cuda'\n",
    "num_classes = 18\n",
    "genre_file = 'data/ml1m/content/dataset/genres.txt'\n",
    "save_golder_label = None\n",
    "\n",
    "# excel_path =  \"data/report/experiment_4_hybrid.xlsx\" # chang this\n",
    "# results_path = \"data/inference_results/hybrid.npz\" # chang this\n",
    "\n",
    "excel_path =  None\n",
    "results_path = None\n",
    "\n",
    "# helper functions\n",
    "def decode_label(output_probability):\n",
    "    output_label = []\n",
    "    for each_output in output_probability:\n",
    "        output_label.append([0 if x < threshold_decode else 1 for x in each_output])\n",
    "    return output_label\n",
    "\n",
    "# components \n",
    "model = HybridMovieGenreModule.load_from_checkpoint(ckpt_path)\n",
    "test_set = HybridMovieGenreDataset(\n",
    "    set='ensemble_test',\n",
    "    data_file='data/ml1m/content/dataset/movies_test.dat',\n",
    "    folder_img_path='data/ml1m/content/dataset/ml1m-images',\n",
    "    genre_file=genre_file\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=64,\n",
    "    num_workers=32,\n",
    "    pin_memory=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# compute\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "golden_label = []\n",
    "predict_label = []\n",
    "predict_probs = []\n",
    "\n",
    "f1 = MultilabelF1Score(num_labels=num_classes, threshold=threshold_decode, average='macro')\n",
    "f1 = f1.to(device)\n",
    "f1_all = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for text_input_ids, text_attention_mask, image_input, genre_tensor in test_loader:\n",
    "        text_input_ids = text_input_ids.to(device)\n",
    "        text_attention_mask = text_attention_mask.to(device)\n",
    "        image_input = image_input.to(device)\n",
    "        genre_tensor = genre_tensor.to(device)\n",
    "        \n",
    "        probs = model(text_input_ids, text_attention_mask, image_input)\n",
    "        preds = torch.tensor(decode_label(probs), device=\"cuda\")\n",
    "        \n",
    "        predict_probs.extend(probs.cpu().numpy())\n",
    "        predict_label.extend(preds.cpu().numpy())\n",
    "        golden_label.extend(genre_tensor.cpu().numpy())\n",
    "        \n",
    "        f1_batch = f1(probs, genre_tensor)\n",
    "        f1_all += f1_batch\n",
    "\n",
    "print('F1 (from baseline notebooks): ', f1_all/len(test_loader))\n",
    "\n",
    "# report\n",
    "predict_probs = np.array(predict_probs)\n",
    "predict_label = np.array(predict_label)\n",
    "golden_label = np.array(golden_label)\n",
    "\n",
    "with open(genre_file, 'r') as f:\n",
    "    genre_all = f.readlines()\n",
    "genre_all = [x.replace('\\n', '') for x in genre_all]\n",
    "print(\"\\n Classification reports\")\n",
    "print(classification_report(golden_label, predict_label, target_names=genre_all))\n",
    "\n",
    "# export\n",
    "if excel_path is not None:\n",
    "    report = classification_report(golden_label, predict_label, target_names=genre_all, output_dict=True)\n",
    "    df = pd.DataFrame(report)\n",
    "    df = df.transpose()\n",
    "    df.to_excel(excel_path)\n",
    "\n",
    "if results_path is not None:\n",
    "    with open(results_path, 'wb') as f:\n",
    "        np.save(f, predict_probs)\n",
    "\n",
    "if save_golder_label is not None:\n",
    "    with open(save_golder_label, 'wb') as f:\n",
    "        np.save(f, golden_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 (from baseline notebooks):  tensor(0.2840, device='cuda:0')\n",
      "\n",
      " Classification reports\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.10      0.19      0.13        31\n",
      "    Thriller       0.36      0.55      0.44       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.66      0.64      0.65        75\n",
      "      Sci-Fi       0.32      0.65      0.43        48\n",
      "      Comedy       0.48      0.43      0.45       247\n",
      " Documentary       0.17      0.07      0.10        30\n",
      "   Adventure       0.27      0.25      0.26        48\n",
      "   Film-Noir       0.04      0.33      0.08         6\n",
      "   Animation       0.23      0.57      0.33        21\n",
      "     Romance       0.29      0.30      0.29        94\n",
      "       Drama       0.55      0.46      0.50       309\n",
      "     Western       0.15      0.14      0.15        14\n",
      "     Musical       0.14      0.38      0.20        13\n",
      "      Action       0.40      0.46      0.42        90\n",
      "     Mystery       0.09      0.56      0.16        18\n",
      "         War       0.17      0.32      0.22        25\n",
      "  Children's       0.57      0.60      0.59        48\n",
      "\n",
      "   micro avg       0.36      0.44      0.40      1230\n",
      "   macro avg       0.28      0.38      0.30      1230\n",
      "weighted avg       0.42      0.44      0.42      1230\n",
      " samples avg       0.39      0.46      0.40      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from src.models.hybrid_movie_genre_module_v2 import HybridMovieGenreModuleV2\n",
    "from src.data.components.hybrid_movie_genre_dataset_v2 import HybridMovieGenreDatasetv2\n",
    "from torch.utils.data import DataLoader \n",
    "import torch\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# config\n",
    "ckpt_path = \"logs/train/runs/2023-12-26_17-11-33/checkpoints/epoch_029.ckpt\"\n",
    "threshold_decode = 0.3\n",
    "device = 'cuda'\n",
    "num_classes = 18\n",
    "genre_file = 'data/ml1m/content/dataset/genres.txt'\n",
    "save_golder_label = None\n",
    "\n",
    "excel_path =  \"data/report/experiment_4_hybrid_v2.xlsx\" # chang this\n",
    "results_path = \"data/inference_results/hybrid_v2.npz\" # chang this\n",
    "\n",
    "# excel_path =  None\n",
    "# results_path = None\n",
    "\n",
    "# helper functions\n",
    "def decode_label(output_probability):\n",
    "    output_label = []\n",
    "    for each_output in output_probability:\n",
    "        output_label.append([0 if x < threshold_decode else 1 for x in each_output])\n",
    "    return output_label\n",
    "\n",
    "# components \n",
    "model = HybridMovieGenreModuleV2.load_from_checkpoint(ckpt_path)\n",
    "test_set = HybridMovieGenreDatasetv2(\n",
    "    set='ensemble_test',\n",
    "    data_file='data/ml1m/content/dataset/movies_test.dat',\n",
    "    user_file='data/ml1m/content/dataset/users.dat',\n",
    "    rating_file='data/ml1m/content/dataset/ratings.dat',\n",
    "    folder_img_path='data/ml1m/content/dataset/ml1m-images',\n",
    "    genre_file=genre_file\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=64,\n",
    "    num_workers=32,\n",
    "    pin_memory=False,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# compute\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "golden_label = []\n",
    "predict_label = []\n",
    "predict_probs = []\n",
    "\n",
    "f1 = MultilabelF1Score(num_labels=num_classes, threshold=threshold_decode, average='macro')\n",
    "f1 = f1.to(device)\n",
    "f1_all = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (ratings_general, ratings_age, ratings_occupation), text_input_ids, text_attention_mask, image_input, genre_tensor in test_loader:\n",
    "        ratings_general = ratings_general.to(device)\n",
    "        ratings_age = ratings_age.to(device)\n",
    "        ratings_occupation = ratings_occupation.to(device)\n",
    "        text_input_ids = text_input_ids.to(device)\n",
    "        text_attention_mask = text_attention_mask.to(device)\n",
    "        image_input = image_input.to(device)\n",
    "        genre_tensor = genre_tensor.to(device)\n",
    "        \n",
    "        user_rating = (ratings_general, ratings_age, ratings_occupation)\n",
    "        probs = model(user_rating, text_input_ids, text_attention_mask, image_input)\n",
    "        preds = torch.tensor(decode_label(probs), device=\"cuda\")\n",
    "        \n",
    "        predict_probs.extend(probs.cpu().numpy())\n",
    "        predict_label.extend(preds.cpu().numpy())\n",
    "        golden_label.extend(genre_tensor.cpu().numpy())\n",
    "        \n",
    "        f1_batch = f1(probs, genre_tensor)\n",
    "        f1_all += f1_batch\n",
    "\n",
    "print('F1 (from baseline notebooks): ', f1_all/len(test_loader))\n",
    "\n",
    "# report\n",
    "predict_probs = np.array(predict_probs)\n",
    "predict_label = np.array(predict_label)\n",
    "golden_label = np.array(golden_label)\n",
    "\n",
    "with open(genre_file, 'r') as f:\n",
    "    genre_all = f.readlines()\n",
    "genre_all = [x.replace('\\n', '') for x in genre_all]\n",
    "print(\"\\n Classification reports\")\n",
    "print(classification_report(golden_label, predict_label, target_names=genre_all))\n",
    "\n",
    "# export\n",
    "if excel_path is not None:\n",
    "    report = classification_report(golden_label, predict_label, target_names=genre_all, output_dict=True)\n",
    "    df = pd.DataFrame(report)\n",
    "    df = df.transpose()\n",
    "    df.to_excel(excel_path)\n",
    "\n",
    "if results_path is not None:\n",
    "    with open(results_path, 'wb') as f:\n",
    "        np.save(f, predict_probs)\n",
    "\n",
    "if save_golder_label is not None:\n",
    "    with open(save_golder_label, 'wb') as f:\n",
    "        np.save(f, golden_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def decode_label(output_probability):\n",
    "    output_label = []\n",
    "    for each_output in output_probability:\n",
    "        output_label.append([0 if x < 0.3 else 1 for x in each_output])\n",
    "    return np.array(output_label)\n",
    "\n",
    "genre_file = 'data/ml1m/content/dataset/genres.txt'\n",
    "with open(genre_file, 'r') as f:\n",
    "    genre_all = f.readlines()\n",
    "genre_all = [x.replace('\\n', '') for x in genre_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "index_not_images = [\n",
    "    21, 37, 60, 75, 76, 93, 101, 112494, 117, 124, 125, 129, 139, 141, 153,\n",
    "    155, 161, 163, 167, 172548, 203, 205270, 213, 222, 234, 238, 240, 249, 254,\n",
    "    256, 257, 267588, 283, 284, 290, 354479, 360292, 372, 374306, 390, 391710,\n",
    "    403, 405722467, 408, 451195, 470, 471, 481, 484171, 501, 504, 508, 515, 516,\n",
    "    522, 5452, 553, 561, 567, 572510, 576, 590650, 586, 596, 612, 633, 643, 661410346,\n",
    "    678297, 681, 703, 724, 726, 729, 732164477, 743, 745302, 748, 753239, 760, 762, 767,\n",
    "    772\n",
    "]\n",
    "print(len(index_not_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden_label_results = \"data/inference_results/golden_label.npz\"\n",
    "text_model_results = \"data/inference_results/text_model.npz\"\n",
    "\n",
    "vgg19_datav2_results = \"data/inference_results/vgg19_datav2.npz\"\n",
    "resnet50_datav2_results = \"data/inference_results/renet50_datav2.npz\"\n",
    "\n",
    "oversampling_20ep_results = \"data/inference_results/oversampling_20ep.npz\"\n",
    "preprocessing_base_20ep_results = \"data/inference_results/preprocessing_base_20ep.npz\"\n",
    "\n",
    "hybrid_results = \"data/inference_results/hybrid.npz\"\n",
    "hybrid_v2_results = \"data/inference_results/hybrid_v2.npz\"\n",
    "\n",
    "with open(vgg19_datav2_results, \"rb\") as f:\n",
    "    vgg19_datav2 = np.load(f)\n",
    "\n",
    "with open(text_model_results, \"rb\") as f:\n",
    "    text_model = np.load(f)\n",
    "    \n",
    "with open(resnet50_datav2_results, \"rb\") as f:\n",
    "    resnet50_datav2 = np.load(f)\n",
    "\n",
    "with open(hybrid_results, \"rb\") as f:\n",
    "    hybrid = np.load(f)\n",
    "    \n",
    "with open(hybrid_v2_results, \"rb\") as f:\n",
    "    hybrid_v2 = np.load(f)\n",
    "\n",
    "with open(oversampling_20ep_results, \"rb\") as f:\n",
    "    oversampling_20ep = np.load(f)\n",
    "\n",
    "with open(preprocessing_base_20ep_results, \"rb\") as f:\n",
    "    preprocessing_base_20ep = np.load(f)\n",
    "    \n",
    "with open(golden_label_results, \"rb\") as f:\n",
    "    golden_label = np.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_datav2_label = decode_label(vgg19_datav2)\n",
    "resnet50_datav2_label = decode_label(resnet50_datav2)\n",
    "\n",
    "oversampling_20ep_label = decode_label(oversampling_20ep)\n",
    "preprocessing_base_20ep_label = decode_label(preprocessing_base_20ep)\n",
    "text_model_label = decode_label(text_model)\n",
    "\n",
    "hybrid_label = decode_label(hybrid)\n",
    "hybrid_v2_label = decode_label(hybrid_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.10      0.19      0.13        31\n",
      "    Thriller       0.36      0.55      0.44       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.66      0.64      0.65        75\n",
      "      Sci-Fi       0.32      0.65      0.43        48\n",
      "      Comedy       0.48      0.43      0.45       247\n",
      " Documentary       0.17      0.07      0.10        30\n",
      "   Adventure       0.27      0.25      0.26        48\n",
      "   Film-Noir       0.04      0.33      0.08         6\n",
      "   Animation       0.23      0.57      0.33        21\n",
      "     Romance       0.29      0.30      0.29        94\n",
      "       Drama       0.55      0.46      0.50       309\n",
      "     Western       0.15      0.14      0.15        14\n",
      "     Musical       0.14      0.38      0.20        13\n",
      "      Action       0.40      0.46      0.42        90\n",
      "     Mystery       0.09      0.56      0.16        18\n",
      "         War       0.17      0.32      0.22        25\n",
      "  Children's       0.57      0.60      0.59        48\n",
      "\n",
      "   micro avg       0.36      0.44      0.40      1230\n",
      "   macro avg       0.28      0.38      0.30      1230\n",
      "weighted avg       0.42      0.44      0.42      1230\n",
      " samples avg       0.39      0.46      0.40      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(golden_label, hybrid_v2_label, target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_decode_label(output_probability, threshold):\n",
    "    output_label = []\n",
    "    for each_output in output_probability:\n",
    "        output_label.append([0 if x < threshold else 1 for x in each_output])\n",
    "    return np.array(output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.11      0.10      0.10        31\n",
      "    Thriller       0.47      0.41      0.43       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.75      0.59      0.66        75\n",
      "      Sci-Fi       0.71      0.62      0.67        48\n",
      "      Comedy       0.52      0.66      0.59       247\n",
      " Documentary       0.10      0.40      0.16        30\n",
      "   Adventure       0.45      0.27      0.34        48\n",
      "   Film-Noir       0.00      0.00      0.00         6\n",
      "   Animation       0.65      0.71      0.68        21\n",
      "     Romance       0.31      0.17      0.22        94\n",
      "       Drama       0.50      0.72      0.59       309\n",
      "     Western       0.38      0.36      0.37        14\n",
      "     Musical       0.15      0.15      0.15        13\n",
      "      Action       0.43      0.50      0.46        90\n",
      "     Mystery       0.25      0.17      0.20        18\n",
      "         War       0.29      0.08      0.12        25\n",
      "  Children's       0.60      0.62      0.61        48\n",
      "\n",
      "   micro avg       0.46      0.53      0.49      1230\n",
      "   macro avg       0.37      0.36      0.35      1230\n",
      "weighted avg       0.47      0.53      0.49      1230\n",
      " samples avg       0.46      0.55      0.47      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# hard voting 1\n",
    "print(classification_report(golden_label, hard_decode_label(\n",
    "    oversampling_20ep_label + preprocessing_base_20ep_label + resnet50_datav2_label + vgg19_datav2_label, \n",
    "    2\n",
    "), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.19      0.10      0.13        31\n",
      "    Thriller       0.55      0.36      0.43       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.76      0.55      0.64        75\n",
      "      Sci-Fi       0.74      0.58      0.65        48\n",
      "      Comedy       0.56      0.59      0.57       247\n",
      " Documentary       0.10      0.40      0.16        30\n",
      "   Adventure       0.53      0.21      0.30        48\n",
      "   Film-Noir       0.00      0.00      0.00         6\n",
      "   Animation       0.71      0.71      0.71        21\n",
      "     Romance       0.40      0.13      0.19        94\n",
      "       Drama       0.51      0.71      0.59       309\n",
      "     Western       0.43      0.21      0.29        14\n",
      "     Musical       0.18      0.15      0.17        13\n",
      "      Action       0.51      0.40      0.45        90\n",
      "     Mystery       0.38      0.17      0.23        18\n",
      "         War       0.25      0.04      0.07        25\n",
      "  Children's       0.72      0.60      0.66        48\n",
      "\n",
      "   micro avg       0.50      0.49      0.49      1230\n",
      "   macro avg       0.42      0.33      0.35      1230\n",
      "weighted avg       0.51      0.49      0.48      1230\n",
      " samples avg       0.48      0.52      0.46      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# hard voting 2\n",
    "print(classification_report(golden_label, hard_decode_label(\n",
    "    oversampling_20ep_label + preprocessing_base_20ep_label + resnet50_datav2_label + vgg19_datav2_label + hybrid_label + hybrid_v2_label, \n",
    "    3\n",
    "), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_decode_label(output_probability, factor):\n",
    "    output_probability = output_probability / factor\n",
    "    output_label = []\n",
    "    for each_output in output_probability:\n",
    "        output_label.append([0 if x < 0.3 else 1 for x in each_output])\n",
    "    return np.array(output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.17      0.19      0.18        31\n",
      "    Thriller       0.43      0.46      0.45       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.83      0.64      0.72        75\n",
      "      Sci-Fi       0.58      0.71      0.64        48\n",
      "      Comedy       0.48      0.65      0.55       247\n",
      " Documentary       0.25      0.10      0.14        30\n",
      "   Adventure       0.38      0.35      0.37        48\n",
      "   Film-Noir       0.00      0.00      0.00         6\n",
      "   Animation       0.61      0.52      0.56        21\n",
      "     Romance       0.33      0.32      0.32        94\n",
      "       Drama       0.51      0.72      0.59       309\n",
      "     Western       0.36      0.29      0.32        14\n",
      "     Musical       0.19      0.23      0.21        13\n",
      "      Action       0.38      0.48      0.42        90\n",
      "     Mystery       0.29      0.28      0.29        18\n",
      "         War       0.27      0.16      0.20        25\n",
      "  Children's       0.58      0.54      0.56        48\n",
      "\n",
      "   micro avg       0.47      0.54      0.50      1230\n",
      "   macro avg       0.37      0.37      0.36      1230\n",
      "weighted avg       0.46      0.54      0.49      1230\n",
      " samples avg       0.49      0.57      0.49      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(golden_label, soft_decode_label(\n",
    "    oversampling_20ep + preprocessing_base_20ep + vgg19_datav2 + hybrid_v2, \n",
    "    4\n",
    "), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.13      0.16      0.14        31\n",
      "    Thriller       0.40      0.42      0.41       106\n",
      "     Fantasy       1.00      0.14      0.25         7\n",
      "      Horror       0.65      0.64      0.64        75\n",
      "      Sci-Fi       0.69      0.50      0.58        48\n",
      "      Comedy       0.49      0.72      0.58       247\n",
      " Documentary       0.10      0.43      0.17        30\n",
      "   Adventure       0.26      0.27      0.27        48\n",
      "   Film-Noir       0.50      0.17      0.25         6\n",
      "   Animation       0.52      0.76      0.62        21\n",
      "     Romance       0.36      0.19      0.25        94\n",
      "       Drama       0.47      0.83      0.60       309\n",
      "     Western       0.33      0.14      0.20        14\n",
      "     Musical       0.21      0.31      0.25        13\n",
      "      Action       0.42      0.53      0.47        90\n",
      "     Mystery       0.33      0.11      0.17        18\n",
      "         War       0.40      0.16      0.23        25\n",
      "  Children's       0.56      0.65      0.60        48\n",
      "\n",
      "   micro avg       0.43      0.58      0.50      1230\n",
      "   macro avg       0.44      0.40      0.37      1230\n",
      "weighted avg       0.45      0.58      0.49      1230\n",
      " samples avg       0.44      0.61      0.48      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# soft voting 2\n",
    "predict_probs = (vgg19_datav2 + text_model + resnet50_datav2 + 2 * hybrid)/4.0\n",
    "predict_label = decode_label(predict_probs)\n",
    "\n",
    "print(classification_report(golden_label, predict_label, target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.13      0.16      0.14        31\n",
      "    Thriller       0.40      0.42      0.41       106\n",
      "     Fantasy       0.03      0.29      0.05         7\n",
      "      Horror       0.65      0.64      0.64        75\n",
      "      Sci-Fi       0.69      0.50      0.58        48\n",
      "      Comedy       0.49      0.72      0.58       247\n",
      " Documentary       0.10      0.43      0.17        30\n",
      "   Adventure       0.26      0.27      0.27        48\n",
      "   Film-Noir       0.50      0.17      0.25         6\n",
      "   Animation       0.52      0.76      0.62        21\n",
      "     Romance       0.36      0.19      0.25        94\n",
      "       Drama       0.47      0.83      0.60       309\n",
      "     Western       0.33      0.14      0.20        14\n",
      "     Musical       0.21      0.31      0.25        13\n",
      "      Action       0.42      0.53      0.47        90\n",
      "     Mystery       0.33      0.11      0.17        18\n",
      "         War       0.40      0.16      0.23        25\n",
      "  Children's       0.56      0.65      0.60        48\n",
      "\n",
      "   micro avg       0.42      0.58      0.48      1230\n",
      "   macro avg       0.38      0.40      0.36      1230\n",
      "weighted avg       0.44      0.58      0.48      1230\n",
      " samples avg       0.43      0.61      0.48      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_probs_copy = predict_probs.copy()\n",
    "predict_label_copy = predict_label.copy()\n",
    "golden_label_copy = golden_label.astype(int)\n",
    "\n",
    "Children = 17\n",
    "Adventure = 7\n",
    "Comedy = 5\n",
    "Action = 14\n",
    "SciFi = 4\n",
    "Drama = 11\n",
    "Fantasy = 2\n",
    "Romance = 10\n",
    "\n",
    "Children_s = 5\n",
    "Adventure_s = 5\n",
    "Comedy_s = 2\n",
    "Action_s = 2\n",
    "SciFi_s = 2\n",
    "Drama_s = 1\n",
    "Romance_s = 1\n",
    "\n",
    "threshold_fantasy = 6\n",
    "\n",
    "for i, predict in enumerate(predict_label_copy):\n",
    "    fantasy_score = 0\n",
    "    fantasy_score += Children_s if predict[Children] == 1 else 0\n",
    "    fantasy_score += Adventure_s if predict[Adventure] == 1 else 0\n",
    "    fantasy_score += Comedy_s if predict[Comedy] == 1 else 0\n",
    "    fantasy_score += Action_s if predict[Action] == 1 else 0\n",
    "    fantasy_score += SciFi_s if predict[SciFi] == 1 else 0\n",
    "    fantasy_score += Drama_s if predict[Drama] == 1 else 0    \n",
    "    fantasy_score += Romance_s if predict[Romance] == 1 else 0\n",
    "\n",
    "    \n",
    "    if fantasy_score >= threshold_fantasy:\n",
    "        predict[Fantasy] = 1\n",
    "#         if(golden_label[i][Fantasy] == 1 and predict[Fantasy] == 1):\n",
    "\n",
    "\n",
    "                                                       \n",
    "print(classification_report(golden_label, predict_label_copy, target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.07      0.13      0.09        31\n",
      "    Thriller       0.34      0.30      0.32       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.84      0.56      0.67        75\n",
      "      Sci-Fi       0.52      0.46      0.49        48\n",
      "      Comedy       0.47      0.56      0.51       247\n",
      " Documentary       0.14      0.03      0.05        30\n",
      "   Adventure       0.26      0.29      0.27        48\n",
      "   Film-Noir       0.14      0.17      0.15         6\n",
      "   Animation       0.29      0.19      0.23        21\n",
      "     Romance       0.33      0.15      0.21        94\n",
      "       Drama       0.51      0.57      0.54       309\n",
      "     Western       0.21      0.21      0.21        14\n",
      "     Musical       0.17      0.23      0.19        13\n",
      "      Action       0.39      0.41      0.40        90\n",
      "     Mystery       0.31      0.28      0.29        18\n",
      "         War       0.26      0.20      0.23        25\n",
      "  Children's       0.50      0.44      0.47        48\n",
      "\n",
      "   micro avg       0.43      0.42      0.43      1230\n",
      "   macro avg       0.32      0.29      0.30      1230\n",
      "weighted avg       0.43      0.42      0.42      1230\n",
      " samples avg       0.43      0.45      0.41      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(golden_label, decode_label(text_model), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.17      0.13      0.15        31\n",
      "    Thriller       0.41      0.30      0.35       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.38      0.27      0.31        75\n",
      "      Sci-Fi       0.40      0.17      0.24        48\n",
      "      Comedy       0.44      0.80      0.57       247\n",
      " Documentary       0.10      0.40      0.16        30\n",
      "   Adventure       0.11      0.02      0.04        48\n",
      "   Film-Noir       0.00      0.00      0.00         6\n",
      "   Animation       0.63      0.81      0.71        21\n",
      "     Romance       0.17      0.05      0.08        94\n",
      "       Drama       0.41      0.76      0.53       309\n",
      "     Western       0.10      0.07      0.08        14\n",
      "     Musical       0.00      0.00      0.00        13\n",
      "      Action       0.31      0.42      0.36        90\n",
      "     Mystery       0.00      0.00      0.00        18\n",
      "         War       0.00      0.00      0.00        25\n",
      "  Children's       0.67      0.42      0.51        48\n",
      "\n",
      "   micro avg       0.38      0.48      0.42      1230\n",
      "   macro avg       0.24      0.26      0.23      1230\n",
      "weighted avg       0.35      0.48      0.38      1230\n",
      " samples avg       0.37      0.50      0.41      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(golden_label, decode_label(vgg19_datav2), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.15      0.10      0.12        31\n",
      "    Thriller       0.30      0.32      0.31       106\n",
      "     Fantasy       0.07      0.14      0.10         7\n",
      "      Horror       0.36      0.21      0.27        75\n",
      "      Sci-Fi       0.36      0.33      0.34        48\n",
      "      Comedy       0.74      0.30      0.43       247\n",
      " Documentary       0.09      0.40      0.15        30\n",
      "   Adventure       0.00      0.00      0.00        48\n",
      "   Film-Noir       0.11      0.17      0.13         6\n",
      "   Animation       0.32      0.67      0.43        21\n",
      "     Romance       0.29      0.13      0.18        94\n",
      "       Drama       0.65      0.26      0.37       309\n",
      "     Western       0.25      0.29      0.27        14\n",
      "     Musical       0.20      0.38      0.26        13\n",
      "      Action       0.34      0.30      0.32        90\n",
      "     Mystery       0.00      0.00      0.00        18\n",
      "         War       0.08      0.04      0.05        25\n",
      "  Children's       0.35      0.58      0.43        48\n",
      "\n",
      "   micro avg       0.31      0.27      0.29      1230\n",
      "   macro avg       0.26      0.26      0.23      1230\n",
      "weighted avg       0.45      0.27      0.31      1230\n",
      " samples avg       0.25      0.26      0.24      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(golden_label, decode_label(resnet50_datav2), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = vgg19_datav2[:, 0]\n",
    "col.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vgg19_datav2_results, \"rb\") as f:\n",
    "    vgg19_datav2 = np.load(f)\n",
    "\n",
    "with open(text_model_results, \"rb\") as f:\n",
    "    text_model = np.load(f)\n",
    "    \n",
    "with open(resnet50_datav2_results, \"rb\") as f:\n",
    "    resnet50_datav2 = np.load(f)\n",
    "\n",
    "with open(hybrid_results, \"rb\") as f:\n",
    "    hybrid = np.load(f)\n",
    "    \n",
    "with open(hybrid_v2_results, \"rb\") as f:\n",
    "    hybrid_v2 = np.load(f)\n",
    "\n",
    "with open(oversampling_20ep_results, \"rb\") as f:\n",
    "    oversampling_20ep = np.load(f)\n",
    "\n",
    "with open(preprocessing_base_20ep_results, \"rb\") as f:\n",
    "    preprocessing_base_20ep = np.load(f)\n",
    "    \n",
    "with open(golden_label_results, \"rb\") as f:\n",
    "    golden_label = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_models = (vgg19_datav2 + resnet50_datav2) / 2.0\n",
    "text_models = (text_model + oversampling_20ep + preprocessing_base_20ep) / 3.0\n",
    "hybrid_models = (hybrid + hybrid_v2) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.18      0.06      0.10        31\n",
      "    Thriller       0.36      0.29      0.32       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.54      0.25      0.35        75\n",
      "      Sci-Fi       0.39      0.23      0.29        48\n",
      "      Comedy       0.63      0.52      0.57       247\n",
      " Documentary       0.10      0.40      0.15        30\n",
      "   Adventure       0.00      0.00      0.00        48\n",
      "   Film-Noir       0.00      0.00      0.00         6\n",
      "   Animation       0.47      0.71      0.57        21\n",
      "     Romance       0.32      0.09      0.13        94\n",
      "       Drama       0.50      0.51      0.50       309\n",
      "     Western       0.25      0.14      0.18        14\n",
      "     Musical       0.20      0.23      0.21        13\n",
      "      Action       0.41      0.42      0.42        90\n",
      "     Mystery       0.00      0.00      0.00        18\n",
      "         War       0.25      0.04      0.07        25\n",
      "  Children's       0.48      0.48      0.48        48\n",
      "\n",
      "   micro avg       0.43      0.37      0.40      1230\n",
      "   macro avg       0.28      0.24      0.24      1230\n",
      "weighted avg       0.43      0.37      0.38      1230\n",
      " samples avg       0.36      0.38      0.35      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(golden_label, decode_label(images_models), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.12      0.23      0.16        31\n",
      "    Thriller       0.40      0.40      0.40       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.82      0.65      0.73        75\n",
      "      Sci-Fi       0.55      0.60      0.57        48\n",
      "      Comedy       0.47      0.67      0.56       247\n",
      " Documentary       0.11      0.07      0.08        30\n",
      "   Adventure       0.31      0.38      0.34        48\n",
      "   Film-Noir       0.33      0.17      0.22         6\n",
      "   Animation       0.56      0.24      0.33        21\n",
      "     Romance       0.31      0.31      0.31        94\n",
      "       Drama       0.50      0.71      0.59       309\n",
      "     Western       0.16      0.21      0.18        14\n",
      "     Musical       0.20      0.23      0.21        13\n",
      "      Action       0.33      0.43      0.38        90\n",
      "     Mystery       0.29      0.28      0.29        18\n",
      "         War       0.14      0.12      0.13        25\n",
      "  Children's       0.44      0.48      0.46        48\n",
      "\n",
      "   micro avg       0.43      0.52      0.47      1230\n",
      "   macro avg       0.34      0.34      0.33      1230\n",
      "weighted avg       0.43      0.52      0.47      1230\n",
      " samples avg       0.45      0.55      0.47      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(golden_label, decode_label(text_models), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.15      0.23      0.18        31\n",
      "    Thriller       0.39      0.51      0.44       106\n",
      "     Fantasy       0.00      0.00      0.00         7\n",
      "      Horror       0.69      0.65      0.67        75\n",
      "      Sci-Fi       0.38      0.62      0.48        48\n",
      "      Comedy       0.50      0.45      0.48       247\n",
      " Documentary       0.22      0.07      0.10        30\n",
      "   Adventure       0.29      0.27      0.28        48\n",
      "   Film-Noir       0.05      0.33      0.09         6\n",
      "   Animation       0.33      0.67      0.44        21\n",
      "     Romance       0.31      0.29      0.30        94\n",
      "       Drama       0.56      0.49      0.52       309\n",
      "     Western       0.18      0.14      0.16        14\n",
      "     Musical       0.14      0.31      0.19        13\n",
      "      Action       0.42      0.42      0.42        90\n",
      "     Mystery       0.10      0.50      0.17        18\n",
      "         War       0.20      0.28      0.23        25\n",
      "  Children's       0.62      0.65      0.63        48\n",
      "\n",
      "   micro avg       0.40      0.45      0.42      1230\n",
      "   macro avg       0.31      0.38      0.32      1230\n",
      "weighted avg       0.44      0.45      0.44      1230\n",
      " samples avg       0.41      0.47      0.41      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(golden_label, decode_label(hybrid_models), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_models = (vgg19_datav2 + resnet50_datav2) / 2.0\n",
    "text_models = (text_model + oversampling_20ep + preprocessing_base_20ep) / 3.0\n",
    "hybrid_models = (hybrid + hybrid_v2) / 2.0\n",
    "\n",
    "with open(genre_file, 'r') as f:\n",
    "    genre_all = f.readlines()\n",
    "genre_all = [x.replace('\\n', '') for x in genre_all]\n",
    "\n",
    "# ensemble_strategy = {\n",
    "#     \"text\": [\"Horror\", \"Sci-Fi\", \"Documentary\", \"Adventure\", \"Film-Noir\", \"Romance\", \"Western\", \"Musical\", \"Action\", \"War\"],\n",
    "#     \"image\": [\"Crime\", \"Thriller\", \"Animation\", \"Mystery\", \"Children's\"],\n",
    "#     \"both\": [\"Fantasy\", \"Comedy\", \"Drama\"]\n",
    "# }\n",
    "\n",
    "ensemble_strategy = {\n",
    "    \"image\": [\"Comedy\", \"Musical\"],\n",
    "    \"text\": [\"Horror\", \"Film-Noir\", \"Romance\", \"Drama\", \"Mystery\"],\n",
    "    \"hybrid\": [\"Crime\", \"Thriller\", \"Action\", \"War\", \"Children's\"],\n",
    "    \"only-hybrid\": [\"Fantasy\", \"Animation\"],\n",
    "    \"only-vgg\": [\"Documentary\"],\n",
    "    \"only-resnet\": [\"Western\", \"Musical\"],\n",
    "    \"only-oversampling\": [\"Adventure\"],\n",
    "    \"only-preprocessing\": [\"Sci-Fi\"],\n",
    "}\n",
    "\n",
    "cols = []\n",
    "for i in range(18):\n",
    "    \n",
    "    genre = genre_all[i]\n",
    "    # print(i, genre)\n",
    "    \n",
    "    images_col = images_models[:, i]\n",
    "    text_col = text_models[:, i]\n",
    "    hybrid_col = hybrid_models[:, i]\n",
    "    only_hybrid_col = hybrid[:, i]\n",
    "    only_vgg_col = vgg19_datav2[:, i]\n",
    "    only_resnet_col = resnet50_datav2[:, i]\n",
    "    only_oversampling_col = oversampling_20ep[:, i]\n",
    "    only_processing_col = preprocessing_base_20ep[:, i]\n",
    "    \n",
    "    if genre in ensemble_strategy[\"text\"]:\n",
    "        cols.append(text_col)\n",
    "    elif genre in ensemble_strategy[\"image\"]:\n",
    "        cols.append(images_col)\n",
    "    elif genre in ensemble_strategy[\"hybrid\"]:\n",
    "        cols.append(hybrid_col)\n",
    "    elif genre in ensemble_strategy[\"only-hybrid\"]:\n",
    "        cols.append(only_hybrid_col)\n",
    "    elif genre in ensemble_strategy[\"only-vgg\"]:\n",
    "        cols.append(only_vgg_col)\n",
    "    elif genre in ensemble_strategy[\"only-resnet\"]:\n",
    "        cols.append(only_resnet_col)\n",
    "    elif genre in ensemble_strategy[\"only-oversampling\"]:\n",
    "        cols.append(only_oversampling_col)\n",
    "    elif genre in ensemble_strategy[\"only-preprocessing\"]:\n",
    "        cols.append(only_processing_col)\n",
    "    else:\n",
    "        print(genre)\n",
    "\n",
    "# print(len(cols))\n",
    "cols = np.array(cols)\n",
    "# print(cols.shape)\n",
    "cols = np.transpose(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg_19 documentary\n",
    "# resnet_50 western musical\n",
    "# oversampling adventure\n",
    "# preprocessing scifi\n",
    "# hybrid animation\n",
    "\n",
    "# hard voting scifi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.15      0.23      0.18        31\n",
      "    Thriller       0.39      0.51      0.44       106\n",
      "     Fantasy       1.00      0.14      0.25         7\n",
      "      Horror       0.82      0.65      0.73        75\n",
      "      Sci-Fi       0.59      0.62      0.61        48\n",
      "      Comedy       0.63      0.52      0.57       247\n",
      " Documentary       0.10      0.40      0.16        30\n",
      "   Adventure       0.29      0.46      0.35        48\n",
      "   Film-Noir       0.33      0.17      0.22         6\n",
      "   Animation       0.57      0.76      0.65        21\n",
      "     Romance       0.31      0.31      0.31        94\n",
      "       Drama       0.50      0.71      0.59       309\n",
      "     Western       0.25      0.29      0.27        14\n",
      "     Musical       0.20      0.23      0.21        13\n",
      "      Action       0.42      0.42      0.42        90\n",
      "     Mystery       0.29      0.28      0.29        18\n",
      "         War       0.20      0.28      0.23        25\n",
      "  Children's       0.62      0.65      0.63        48\n",
      "\n",
      "   micro avg       0.44      0.53      0.48      1230\n",
      "   macro avg       0.43      0.42      0.39      1230\n",
      "weighted avg       0.48      0.53      0.50      1230\n",
      " samples avg       0.45      0.56      0.46      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(golden_label, decode_label(cols), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/ensemble_results/custom_v2.npz\"\n",
    "\n",
    "with open(path, 'wb') as f:\n",
    "    np.save(f, cols)\n",
    "\n",
    "with open(path, \"rb\") as f:\n",
    "    cols = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime       0.15      0.23      0.18        31\n",
      "    Thriller       0.39      0.51      0.44       106\n",
      "     Fantasy       1.00      0.14      0.25         7\n",
      "      Horror       0.82      0.65      0.73        75\n",
      "      Sci-Fi       0.59      0.62      0.61        48\n",
      "      Comedy       0.63      0.52      0.57       247\n",
      " Documentary       0.10      0.40      0.16        30\n",
      "   Adventure       0.29      0.46      0.35        48\n",
      "   Film-Noir       0.33      0.17      0.22         6\n",
      "   Animation       0.57      0.76      0.65        21\n",
      "     Romance       0.31      0.31      0.31        94\n",
      "       Drama       0.50      0.71      0.59       309\n",
      "     Western       0.25      0.29      0.27        14\n",
      "     Musical       0.20      0.23      0.21        13\n",
      "      Action       0.42      0.42      0.42        90\n",
      "     Mystery       0.29      0.28      0.29        18\n",
      "         War       0.20      0.28      0.23        25\n",
      "  Children's       0.62      0.65      0.63        48\n",
      "\n",
      "   micro avg       0.44      0.53      0.48      1230\n",
      "   macro avg       0.43      0.42      0.39      1230\n",
      "weighted avg       0.48      0.53      0.50      1230\n",
      " samples avg       0.45      0.56      0.46      1230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/hpc/pad/PAD2003-multi-label-movie-genres/envs/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(golden_label, decode_label(cols), target_names=genre_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sci-fi, Comedy, Documentary, Film-Noir, Drama, Western, Mystery, Children's "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
